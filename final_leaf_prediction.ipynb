{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GGjhBnw5wQNz"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.utils import img_to_array\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras import layers\n",
        "import random\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from tensorflow.keras.layers import Input, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from glob import glob\n",
        "import cv2 as cv\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import Counter\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.regularizers import l2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Nm9METwpe8",
        "outputId": "25f1ce5c-6c5e-441c-ecd6-7f934903afca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction complete!\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = r\"/content/final_leaf.zip\"  # Update this with the actual ZIP file path\n",
        "extract_dir = r\"/content/final_leaf.zip\\all_data\"  # Choose a directory to extract the data\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(\"Extraction complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9xx93_W3wtVg"
      },
      "outputs": [],
      "source": [
        "base_dir = r\"/content/final_leaf.zip\\all_data/leaf2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biySTCVSwtd4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f-C9jB-uwQN2"
      },
      "outputs": [],
      "source": [
        "# Image Parameters\n",
        "img_size = 224\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XH1iAhajwQN2"
      },
      "outputs": [],
      "source": [
        "# Image Data Generators\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2  # Use 20% of data for validation\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbDNLf_vwQN2",
        "outputId": "562c59b7-dfc5-45fb-b83f-feed86f13de9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4230 images belonging to 15 classes.\n"
          ]
        }
      ],
      "source": [
        "# Train Generator\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    subset='training',\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAlxnUj1wQN3",
        "outputId": "99f688c1-72cd-4297-f1f9-2d96cf0c223f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1050 images belonging to 15 classes.\n"
          ]
        }
      ],
      "source": [
        "# Validation Generator\n",
        "validation_generator = data_gen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    subset='validation',\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwQuCpu7wQN4",
        "outputId": "333a73a1-8d01-4920-8052-1c5b9fd1dadb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_generator.num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZW9a2lnwQN4",
        "outputId": "3a6ee964-740d-4383-8a10-b8df5da19d79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Model Definition\n",
        "from tensorflow.keras import layers, models\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(train_generator.num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "DwcQBvPDwQN4",
        "outputId": "129c18b7-dad8-489a-8a6d-1d8882a4377c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">186624</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">47,776,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m186624\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m47,776,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │         \u001b[38;5;34m3,855\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,799,247</span> (182.34 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m47,799,247\u001b[0m (182.34 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,799,247</span> (182.34 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m47,799,247\u001b[0m (182.34 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "07WGMb5DwQN5"
      },
      "outputs": [],
      "source": [
        "# Compile the Model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puew7Z7AwQN5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0GzZqFOwQN5",
        "outputId": "47bbb83a-d853-4a03-9593-19046af662af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 124ms/step - accuracy: 0.3767 - loss: 3.9820 - val_accuracy: 0.7598 - val_loss: 0.7328\n",
            "Epoch 2/7\n",
            "\u001b[1m  1/132\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.8750 - loss: 0.4961"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8750 - loss: 0.4961 - val_accuracy: 0.7520 - val_loss: 0.7698\n",
            "Epoch 3/7\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - accuracy: 0.8857 - loss: 0.3501 - val_accuracy: 0.8369 - val_loss: 0.5001\n",
            "Epoch 4/7\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9688 - loss: 0.1901 - val_accuracy: 0.8262 - val_loss: 0.5174\n",
            "Epoch 5/7\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 157ms/step - accuracy: 0.9285 - loss: 0.2219 - val_accuracy: 0.8164 - val_loss: 0.5683\n",
            "Epoch 6/7\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9062 - loss: 0.2535 - val_accuracy: 0.8047 - val_loss: 0.6724\n",
            "Epoch 7/7\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 158ms/step - accuracy: 0.9705 - loss: 0.1001 - val_accuracy: 0.8516 - val_loss: 0.4340\n"
          ]
        }
      ],
      "source": [
        "# Training the Model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,  # Number of steps per epoch\n",
        "    epochs=7,  # Number of epochs\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size  # Validation steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tOuruAj1nUj",
        "outputId": "fe881538-8e27-463e-b38a-e94a595ba4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model...\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.8536 - loss: 0.4583\n",
            "Validation Accuracy: 85.16%\n"
          ]
        }
      ],
      "source": [
        "# Model Evaluation\n",
        "print(\"Evaluating model...\")\n",
        "val_loss, val_accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "80Z3YDy81nWk"
      },
      "outputs": [],
      "source": [
        "# Function to Load and Preprocess the Image using Pillow\n",
        "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
        "    # Load the image\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    # Resize the image\n",
        "    img = img.resize(target_size)\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = np.array(img)\n",
        "    # Add batch dimension\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    # Scale the image values to [0, 1]\n",
        "    img_array = img_array.astype('float32') / 255.\n",
        "    return img_array\n",
        "\n",
        "# Function to Predict the Class of an Image\n",
        "def predict_image_class(model, image_path, class_indices):\n",
        "    preprocessed_img = load_and_preprocess_image(image_path)\n",
        "    predictions = model.predict(preprocessed_img)\n",
        "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "    predicted_class_name = class_indices[predicted_class_index]\n",
        "    return predicted_class_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK0s4CGCMp-V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQlSMrJD1nZy",
        "outputId": "44aac9a4-5813-4976-cb04-b3d685300a03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'Alstonia Scholaris',\n",
              " 1: 'Arjun',\n",
              " 2: 'Bael',\n",
              " 3: 'Basil',\n",
              " 4: 'Chinar',\n",
              " 5: 'Gauva',\n",
              " 6: 'Jamun',\n",
              " 7: 'Lemon',\n",
              " 8: 'Pomegranate',\n",
              " 9: 'apple',\n",
              " 10: 'cotton',\n",
              " 11: 'grape',\n",
              " 12: 'mango',\n",
              " 13: 'potato',\n",
              " 14: 'tomato'}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a mapping from class indices to class names\n",
        "class_indices = {v: k for k, v in train_generator.class_indices.items()}\n",
        "train_generator.class_indices.items()\n",
        "class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcFowVLp1zZI",
        "outputId": "b2749ed5-41e2-4b13-b7f2-a7f0d1c0b742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Predicted Class Name: grape potato apple cotton mango tomato Alstonia Scholaris Arjun Bael Basil Chinar Gauva Jamun Pomegranate Lemon\n"
          ]
        }
      ],
      "source": [
        "im1=r'/content/final_leaf.zip\\all_data/leaf2/grape/00a962ad-573b-44b1-97ae-912a6bd6e0b0___FAM_L.Blight 1431.JPG' #grape\n",
        "im2=r'/content/final_leaf.zip\\all_data/leaf2/potato/20230712_114353.jpg'  #potato\n",
        "im3=r'/content/final_leaf.zip\\all_data/leaf2/apple/00fca0da-2db3-481b-b98a-9b67bb7b105c___RS_HL 7708.JPG'  #apple\n",
        "im4=r'/content/final_leaf.zip\\all_data/leaf2/cotton/bact17.jpg'  #cotton\n",
        "im5=r'/content/final_leaf.zip\\all_data/leaf2/mango/20211008_125130 (Custom).jpg'  #mango\n",
        "im6=r'/content/final_leaf.zip\\all_data/leaf2/tomato/0a22f50a-5f25-4cf6-816b-76cae94b7f30___GCREC_Bact.Sp 6103.JPG'  #tomato\n",
        "im7=r'/content/final_leaf.zip\\all_data/leaf2/Alstonia Scholaris/0003_0013.JPG' #AS\n",
        "im8=r'/content/final_leaf.zip\\all_data/leaf2/Arjun/0002_0016.JPG'\n",
        "im9=r'/content/final_leaf.zip\\all_data/leaf2/Bael/0016_0016.JPG'\n",
        "im10=r'/content/final_leaf.zip\\all_data/leaf2/Basil/0008_0017.JPG'\n",
        "im11=r'/content/final_leaf.zip\\all_data/leaf2/Chinar/0011_0022.JPG'\n",
        "im12=r'/content/final_leaf.zip\\all_data/leaf2/Gauva/0004_0017.JPG'\n",
        "im13=r'//content/final_leaf.zip\\all_data/leaf2/Jamun/0005_0017.JPG'\n",
        "im14=r'/content/final_leaf.zip\\all_data/leaf2/Pomegranate/0009_0182.JPG'\n",
        "im15=r'/content/final_leaf.zip\\all_data/leaf2/Lemon/0010_0018.JPG'\n",
        "predicted_class_name1 = predict_image_class(model, im1, class_indices)\n",
        "predicted_class_name2 = predict_image_class(model, im2, class_indices)\n",
        "predicted_class_name3 = predict_image_class(model, im3, class_indices)\n",
        "predicted_class_name4 = predict_image_class(model, im4, class_indices)\n",
        "predicted_class_name5 = predict_image_class(model, im5, class_indices)\n",
        "predicted_class_name6 = predict_image_class(model, im6, class_indices)\n",
        "predicted_class_name7 = predict_image_class(model, im7, class_indices)\n",
        "predicted_class_name8 = predict_image_class(model, im8, class_indices)\n",
        "predicted_class_name9 = predict_image_class(model, im9, class_indices)\n",
        "predicted_class_name10 = predict_image_class(model, im10, class_indices)\n",
        "predicted_class_name11 = predict_image_class(model, im11, class_indices)\n",
        "predicted_class_name12= predict_image_class(model, im12, class_indices)\n",
        "predicted_class_name13= predict_image_class(model, im13, class_indices)\n",
        "predicted_class_name14= predict_image_class(model, im14, class_indices)\n",
        "predicted_class_name15= predict_image_class(model, im15, class_indices)\n",
        "# print(predicted_class_name6)\n",
        "# Output the result\n",
        "print(\"Predicted Class Name:\", predicted_class_name1,predicted_class_name2,predicted_class_name3,predicted_class_name4,predicted_class_name5,\n",
        "      predicted_class_name6,predicted_class_name7,predicted_class_name8,predicted_class_name9,predicted_class_name10,predicted_class_name11,\n",
        "      predicted_class_name12,predicted_class_name13,predicted_class_name14,predicted_class_name15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8VnDt5A1zko",
        "outputId": "bef3fdf6-ed0a-4522-ea2d-8d7a02aea982"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('final_leaf_prediction_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M1woL9HwQN5",
        "outputId": "55718bc1-a718-4d70-dd59-0936758c139c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Samples: 2105\n",
            "Validation Samples: 524\n",
            "Batch Size: 32\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train Samples: {train_generator.samples}\")\n",
        "print(f\"Validation Samples: {validation_generator.samples}\")\n",
        "print(f\"Batch Size: {batch_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the model using Keras's load_model function\n",
        "model = load_model(r'C:\\Users\\Arunava Chakraborty\\Desktop\\plant-disease-prediction-cnn-deep-leanring-project-main\\final_leaf_prediction2_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def predict_image(model, image_path, class_indices, target_size=(224, 224)):\n",
        "    # Load and preprocess the image\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img = img.resize(target_size)\n",
        "    img_array = np.expand_dims(np.array(img).astype('float32') / 255.0, axis=0)\n",
        "    \n",
        "    # Make prediction\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
        "    predicted_class_name = class_indices[predicted_class_index]\n",
        "    \n",
        "    return predicted_class_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_indices = {\n",
        "    0: 'Alstonia Scholaris',\n",
        "    1: 'Arjun',\n",
        "    2: 'Bael',\n",
        "    3: 'Basil',\n",
        "    4: 'Chinar',\n",
        "    5: 'Gauva',\n",
        "    6: 'Jamun',\n",
        "    7: 'Lemon',\n",
        "    8: 'Pomegranate',\n",
        "    9: 'apple',\n",
        "    10: 'cotton',\n",
        "    11: 'grape',\n",
        "    12: 'mango',\n",
        "    13: 'potato',\n",
        "    14: 'tomato'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
            "Predicted Class: Pomegranate\n"
          ]
        }
      ],
      "source": [
        "image_path = r'C:\\Users\\Arunava Chakraborty\\Desktop\\plant-disease-prediction-cnn-deep-leanring-project-main\\all_data\\leaf2\\Pomegranate\\0009_0081.JPG'\n",
        "result = predict_image(model, image_path, class_indices)\n",
        "print(\"Predicted Class:\", result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
